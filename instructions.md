# Инструкция по настройке интеграции Groq API (Llama 3.3)

Интеграция ИИ для анализа заявок успешно добавлена в проект!
Она реализована через официальную библиотеку `groq` и работает в качестве фоновой задачи (FastAPI Background Tasks) при создании новой заявки, чтобы не блокировать интерфейс.

## Что вам нужно сделать, чтобы все заработало:

1. **Получить API-ключ Groq**
   - Перейдите на [console.groq.com](https://console.groq.com/keys)
   - Создайте новый API ключ.

2. **Добавить ключ в проект**
   - В папке бэкенда (`c:\Dev\хакатон\Big-nine-team\backend`) в файл `.env` добавьте новую строку:
     ```env
     GROQ_API_KEY=ваш_созданный_api_ключ_здесь
     ```

3. **Установить новые зависимости бэкенда**
   - Был обновлен файл `backend/requirements.txt` (добавлен пакет `groq`).
   - Перед запуском проекта обязательно обновите виртуальное окружение:
     ```bash
     cd backend
     venv\Scripts\activate  # Или `source venv/bin/activate` на Mac/Linux
     pip install -r requirements.txt
     ```

4. **Запустить проект и протестировать**
   - Запустите сервер FastAPI (`uvicorn app.main:app --reload` или через ваш `docker-compose`).
   - Создайте новую заявку. В фоновом режиме система отправит её текст в Groq.
   - Проверьте базу данных (или снова запросите тикет по API) – у него должны появиться заполненные поля `sentiment`, `category` и сгенерированный `ai_response`.

Успехов на хакатоне!
